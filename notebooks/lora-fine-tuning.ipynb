{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c1f22cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"../data/projects.json\"\n",
    "output_file = \"../data/projects.jsonl\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    projects = json.load(f)\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for p in projects:\n",
    "        record = {\n",
    "            \"text\": p[\"text\"],\n",
    "            \"metadata\": {\n",
    "                \"projekt\": p[\"projekt\"],\n",
    "                \"kategorie\": p[\"kategorie\"],\n",
    "                \"datum\": p[\"datum\"]\n",
    "            }\n",
    "        }\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a04257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/face_craft_env/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "W0204 08:15:08.463000 2284 site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b91bc13815444af97cdc53b7d2aaa1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/face_craft_env/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-3B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a975a735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,686,400 || all params: 3,089,625,088 || trainable%: 0.11931544750584314\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c627675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e768fdf50d4a378de5dcb00204a82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89af54ece6aa4bb2951c362b42b94806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14625 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Dataset laden\n",
    "# -------------------------------\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# Originales Dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"../data/projects.jsonl\")[\"train\"]\n",
    "\n",
    "# -------------------------------\n",
    "# Dataset für flexible Instructions erweitern\n",
    "# -------------------------------\n",
    "all_examples = []\n",
    "\n",
    "for ex in dataset:\n",
    "    projekt = ex.get(\"metadata\", {}).get(\"projekt\", \"\")\n",
    "    kategorie = ex.get(\"metadata\", {}).get(\"kategorie\", \"\")\n",
    "    datum = ex.get(\"metadata\", {}).get(\"datum\", \"\")\n",
    "\n",
    "    # Verschiedene mögliche Fragen / Instructions pro Sample\n",
    "    instructions = [\n",
    "        f\"Erkläre das Projekt {projekt} in einem Satz.\",\n",
    "        f\"Wofür war das Projekt {projekt} zuständig?\",\n",
    "        f\"Welche Probleme traten beim Projekt {projekt} auf?\",\n",
    "        f\"Nenne die Kategorie des Projekts {projekt}.\",\n",
    "        f\"Wann fand das Projekt {projekt} statt?\"\n",
    "    ]\n",
    "\n",
    "    # Für jede Instruction ein neues Sample erzeugen\n",
    "    for instr in instructions:\n",
    "        all_examples.append({\n",
    "            \"text\": ex[\"text\"],\n",
    "            \"metadata\": ex[\"metadata\"],\n",
    "            \"instruction\": instr\n",
    "        })\n",
    "\n",
    "# Neues, erweitertes Dataset\n",
    "dataset_expanded = Dataset.from_list(all_examples)\n",
    "\n",
    "# -------------------------------\n",
    "# Tokenisierung\n",
    "# -------------------------------\n",
    "def tokenize_fn(example):\n",
    "    prompt = (\n",
    "        f\"### Instruction:\\n\"\n",
    "        f\"{example['instruction']}\\n\"\n",
    "        f\"Beziehe dich nur auf die Trainingsdaten, erfinde nichts.\\n\\n\"\n",
    "        f\"### Response:\\n\"\n",
    "        f\"{example['text']}\"\n",
    "    )\n",
    "\n",
    "    tokenized_example = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    # Labels für Causal LM\n",
    "    tokenized_example[\"labels\"] = tokenized_example[\"input_ids\"]\n",
    "    return tokenized_example\n",
    "\n",
    "# batched=False → ein Sample pro Map\n",
    "tokenized = dataset_expanded.map(tokenize_fn, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f3d7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Setup\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# Optional: DataCollator für kleine Batches / MPS\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen2-lora\",\n",
    "    per_device_train_batch_size=1,   # MPS sehr klein\n",
    "    gradient_accumulation_steps=8,   # effektiv größere Batch\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-4,              # stabil für LoRA\n",
    "    fp16=False,   # MPS unterstützt kein FP16 in Trainer\n",
    "    bf16=False,   # MPS blockiert BF16\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a780c91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863a5dc24e9c42b4a184be578997dabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/face_craft_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6415, 'grad_norm': 0.9296875, 'learning_rate': 9.981765134938001e-05, 'epoch': 0.01}\n",
      "{'loss': 3.0912, 'grad_norm': 1.3359375, 'learning_rate': 9.963530269876004e-05, 'epoch': 0.01}\n",
      "{'loss': 2.3658, 'grad_norm': 1.8671875, 'learning_rate': 9.945295404814005e-05, 'epoch': 0.02}\n",
      "{'loss': 1.7466, 'grad_norm': 1.71875, 'learning_rate': 9.927060539752007e-05, 'epoch': 0.02}\n",
      "{'loss': 1.4318, 'grad_norm': 2.109375, 'learning_rate': 9.908825674690008e-05, 'epoch': 0.03}\n",
      "{'loss': 1.2845, 'grad_norm': 1.9609375, 'learning_rate': 9.89059080962801e-05, 'epoch': 0.03}\n",
      "{'loss': 1.063, 'grad_norm': 1.984375, 'learning_rate': 9.872355944566011e-05, 'epoch': 0.04}\n",
      "{'loss': 0.9982, 'grad_norm': 2.15625, 'learning_rate': 9.854121079504012e-05, 'epoch': 0.04}\n",
      "{'loss': 1.0415, 'grad_norm': 1.4609375, 'learning_rate': 9.835886214442014e-05, 'epoch': 0.05}\n",
      "{'loss': 0.9298, 'grad_norm': 1.6640625, 'learning_rate': 9.817651349380015e-05, 'epoch': 0.05}\n",
      "{'loss': 0.9564, 'grad_norm': 1.7734375, 'learning_rate': 9.799416484318017e-05, 'epoch': 0.06}\n",
      "{'loss': 0.8327, 'grad_norm': 1.5234375, 'learning_rate': 9.781181619256018e-05, 'epoch': 0.07}\n",
      "{'loss': 0.8099, 'grad_norm': 1.8671875, 'learning_rate': 9.762946754194019e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7625, 'grad_norm': 3.125, 'learning_rate': 9.744711889132021e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7294, 'grad_norm': 1.5859375, 'learning_rate': 9.726477024070022e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7623, 'grad_norm': 2.09375, 'learning_rate': 9.708242159008025e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7525, 'grad_norm': 1.6796875, 'learning_rate': 9.690007293946025e-05, 'epoch': 0.09}\n",
      "{'loss': 0.778, 'grad_norm': 1.8046875, 'learning_rate': 9.671772428884028e-05, 'epoch': 0.1}\n",
      "{'loss': 0.852, 'grad_norm': 1.6484375, 'learning_rate': 9.653537563822029e-05, 'epoch': 0.1}\n",
      "{'loss': 0.6496, 'grad_norm': 2.109375, 'learning_rate': 9.63530269876003e-05, 'epoch': 0.11}\n",
      "{'loss': 0.801, 'grad_norm': 2.3125, 'learning_rate': 9.617067833698032e-05, 'epoch': 0.11}\n",
      "{'loss': 0.583, 'grad_norm': 1.8984375, 'learning_rate': 9.598832968636033e-05, 'epoch': 0.12}\n",
      "{'loss': 0.7489, 'grad_norm': 1.6875, 'learning_rate': 9.580598103574035e-05, 'epoch': 0.13}\n",
      "{'loss': 0.6958, 'grad_norm': 1.34375, 'learning_rate': 9.562363238512036e-05, 'epoch': 0.13}\n",
      "{'loss': 0.7736, 'grad_norm': 1.28125, 'learning_rate': 9.544128373450037e-05, 'epoch': 0.14}\n",
      "{'loss': 0.6827, 'grad_norm': 1.546875, 'learning_rate': 9.525893508388039e-05, 'epoch': 0.14}\n",
      "{'loss': 0.7436, 'grad_norm': 1.4453125, 'learning_rate': 9.50765864332604e-05, 'epoch': 0.15}\n",
      "{'loss': 0.766, 'grad_norm': 1.4609375, 'learning_rate': 9.489423778264041e-05, 'epoch': 0.15}\n",
      "{'loss': 0.718, 'grad_norm': 1.125, 'learning_rate': 9.471188913202043e-05, 'epoch': 0.16}\n",
      "{'loss': 0.669, 'grad_norm': 1.390625, 'learning_rate': 9.452954048140044e-05, 'epoch': 0.16}\n",
      "{'loss': 0.789, 'grad_norm': 1.5, 'learning_rate': 9.434719183078045e-05, 'epoch': 0.17}\n",
      "{'loss': 0.6607, 'grad_norm': 1.40625, 'learning_rate': 9.416484318016047e-05, 'epoch': 0.18}\n",
      "{'loss': 0.6376, 'grad_norm': 1.4375, 'learning_rate': 9.398249452954048e-05, 'epoch': 0.18}\n",
      "{'loss': 0.5963, 'grad_norm': 3.125, 'learning_rate': 9.380014587892049e-05, 'epoch': 0.19}\n",
      "{'loss': 0.7226, 'grad_norm': 1.1328125, 'learning_rate': 9.361779722830051e-05, 'epoch': 0.19}\n",
      "{'loss': 0.719, 'grad_norm': 1.1953125, 'learning_rate': 9.343544857768052e-05, 'epoch': 0.2}\n",
      "{'loss': 0.6638, 'grad_norm': 1.5078125, 'learning_rate': 9.325309992706053e-05, 'epoch': 0.2}\n",
      "{'loss': 0.685, 'grad_norm': 1.453125, 'learning_rate': 9.307075127644056e-05, 'epoch': 0.21}\n",
      "{'loss': 0.6138, 'grad_norm': 1.25, 'learning_rate': 9.288840262582056e-05, 'epoch': 0.21}\n",
      "{'loss': 0.7595, 'grad_norm': 1.4765625, 'learning_rate': 9.270605397520059e-05, 'epoch': 0.22}\n",
      "{'loss': 0.6175, 'grad_norm': 1.1875, 'learning_rate': 9.25237053245806e-05, 'epoch': 0.22}\n",
      "{'loss': 0.7117, 'grad_norm': 1.5, 'learning_rate': 9.234135667396062e-05, 'epoch': 0.23}\n",
      "{'loss': 0.6259, 'grad_norm': 1.359375, 'learning_rate': 9.215900802334063e-05, 'epoch': 0.24}\n",
      "{'loss': 0.6282, 'grad_norm': 1.484375, 'learning_rate': 9.197665937272064e-05, 'epoch': 0.24}\n",
      "{'loss': 0.68, 'grad_norm': 1.3125, 'learning_rate': 9.179431072210066e-05, 'epoch': 0.25}\n",
      "{'loss': 0.5918, 'grad_norm': 1.6953125, 'learning_rate': 9.161196207148067e-05, 'epoch': 0.25}\n",
      "{'loss': 0.6116, 'grad_norm': 1.1796875, 'learning_rate': 9.142961342086069e-05, 'epoch': 0.26}\n",
      "{'loss': 0.5929, 'grad_norm': 0.99609375, 'learning_rate': 9.12472647702407e-05, 'epoch': 0.26}\n",
      "{'loss': 0.6902, 'grad_norm': 1.2421875, 'learning_rate': 9.106491611962072e-05, 'epoch': 0.27}\n",
      "{'loss': 0.6528, 'grad_norm': 1.296875, 'learning_rate': 9.088256746900073e-05, 'epoch': 0.27}\n",
      "{'loss': 0.657, 'grad_norm': 1.140625, 'learning_rate': 9.070021881838074e-05, 'epoch': 0.28}\n",
      "{'loss': 0.616, 'grad_norm': 1.109375, 'learning_rate': 9.051787016776076e-05, 'epoch': 0.28}\n",
      "{'loss': 0.5717, 'grad_norm': 1.21875, 'learning_rate': 9.033552151714077e-05, 'epoch': 0.29}\n",
      "{'loss': 0.7363, 'grad_norm': 1.3125, 'learning_rate': 9.01531728665208e-05, 'epoch': 0.3}\n",
      "{'loss': 0.611, 'grad_norm': 1.8671875, 'learning_rate': 8.99708242159008e-05, 'epoch': 0.3}\n",
      "{'loss': 0.6644, 'grad_norm': 1.0078125, 'learning_rate': 8.978847556528081e-05, 'epoch': 0.31}\n",
      "{'loss': 0.584, 'grad_norm': 1.4765625, 'learning_rate': 8.960612691466084e-05, 'epoch': 0.31}\n",
      "{'loss': 0.6649, 'grad_norm': 1.140625, 'learning_rate': 8.942377826404085e-05, 'epoch': 0.32}\n",
      "{'loss': 0.6832, 'grad_norm': 1.28125, 'learning_rate': 8.924142961342087e-05, 'epoch': 0.32}\n",
      "{'loss': 0.6387, 'grad_norm': 1.0859375, 'learning_rate': 8.905908096280088e-05, 'epoch': 0.33}\n",
      "{'loss': 0.7558, 'grad_norm': 1.609375, 'learning_rate': 8.88767323121809e-05, 'epoch': 0.33}\n",
      "{'loss': 0.6308, 'grad_norm': 0.98828125, 'learning_rate': 8.869438366156091e-05, 'epoch': 0.34}\n",
      "{'loss': 0.62, 'grad_norm': 1.125, 'learning_rate': 8.851203501094092e-05, 'epoch': 0.34}\n",
      "{'loss': 0.6534, 'grad_norm': 1.2578125, 'learning_rate': 8.832968636032094e-05, 'epoch': 0.35}\n",
      "{'loss': 0.624, 'grad_norm': 1.25, 'learning_rate': 8.814733770970095e-05, 'epoch': 0.36}\n",
      "{'loss': 0.6983, 'grad_norm': 1.3125, 'learning_rate': 8.796498905908097e-05, 'epoch': 0.36}\n",
      "{'loss': 0.7189, 'grad_norm': 1.0859375, 'learning_rate': 8.778264040846098e-05, 'epoch': 0.37}\n",
      "{'loss': 0.6663, 'grad_norm': 1.328125, 'learning_rate': 8.760029175784099e-05, 'epoch': 0.37}\n",
      "{'loss': 0.6333, 'grad_norm': 0.8203125, 'learning_rate': 8.741794310722101e-05, 'epoch': 0.38}\n",
      "{'loss': 0.5712, 'grad_norm': 1.1328125, 'learning_rate': 8.723559445660102e-05, 'epoch': 0.38}\n",
      "{'loss': 0.6696, 'grad_norm': 1.21875, 'learning_rate': 8.705324580598105e-05, 'epoch': 0.39}\n",
      "{'loss': 0.6111, 'grad_norm': 1.328125, 'learning_rate': 8.687089715536106e-05, 'epoch': 0.39}\n",
      "{'loss': 0.5395, 'grad_norm': 1.125, 'learning_rate': 8.668854850474108e-05, 'epoch': 0.4}\n",
      "{'loss': 0.636, 'grad_norm': 1.1015625, 'learning_rate': 8.650619985412109e-05, 'epoch': 0.4}\n",
      "{'loss': 0.7044, 'grad_norm': 1.5234375, 'learning_rate': 8.63238512035011e-05, 'epoch': 0.41}\n",
      "{'loss': 0.5694, 'grad_norm': 1.3828125, 'learning_rate': 8.614150255288112e-05, 'epoch': 0.42}\n",
      "{'loss': 0.4915, 'grad_norm': 0.96484375, 'learning_rate': 8.595915390226113e-05, 'epoch': 0.42}\n",
      "{'loss': 0.5831, 'grad_norm': 1.15625, 'learning_rate': 8.577680525164115e-05, 'epoch': 0.43}\n",
      "{'loss': 0.62, 'grad_norm': 1.390625, 'learning_rate': 8.559445660102116e-05, 'epoch': 0.43}\n",
      "{'loss': 0.5683, 'grad_norm': 1.6015625, 'learning_rate': 8.541210795040117e-05, 'epoch': 0.44}\n",
      "{'loss': 0.6558, 'grad_norm': 1.21875, 'learning_rate': 8.522975929978119e-05, 'epoch': 0.44}\n",
      "{'loss': 0.6031, 'grad_norm': 0.89453125, 'learning_rate': 8.50474106491612e-05, 'epoch': 0.45}\n",
      "{'loss': 0.6778, 'grad_norm': 1.265625, 'learning_rate': 8.486506199854122e-05, 'epoch': 0.45}\n",
      "{'loss': 0.5959, 'grad_norm': 1.078125, 'learning_rate': 8.468271334792123e-05, 'epoch': 0.46}\n",
      "{'loss': 0.5181, 'grad_norm': 1.21875, 'learning_rate': 8.450036469730124e-05, 'epoch': 0.46}\n",
      "{'loss': 0.6011, 'grad_norm': 1.265625, 'learning_rate': 8.431801604668126e-05, 'epoch': 0.47}\n",
      "{'loss': 0.6437, 'grad_norm': 1.3359375, 'learning_rate': 8.413566739606127e-05, 'epoch': 0.48}\n",
      "{'loss': 0.56, 'grad_norm': 0.83203125, 'learning_rate': 8.395331874544128e-05, 'epoch': 0.48}\n",
      "{'loss': 0.6537, 'grad_norm': 1.4140625, 'learning_rate': 8.37709700948213e-05, 'epoch': 0.49}\n",
      "{'loss': 0.5494, 'grad_norm': 1.09375, 'learning_rate': 8.358862144420132e-05, 'epoch': 0.49}\n",
      "{'loss': 0.5688, 'grad_norm': 1.171875, 'learning_rate': 8.340627279358132e-05, 'epoch': 0.5}\n",
      "{'loss': 0.6502, 'grad_norm': 1.21875, 'learning_rate': 8.322392414296135e-05, 'epoch': 0.5}\n",
      "{'loss': 0.5551, 'grad_norm': 1.1796875, 'learning_rate': 8.304157549234136e-05, 'epoch': 0.51}\n",
      "{'loss': 0.6748, 'grad_norm': 1.0859375, 'learning_rate': 8.285922684172137e-05, 'epoch': 0.51}\n",
      "{'loss': 0.612, 'grad_norm': 1.125, 'learning_rate': 8.267687819110139e-05, 'epoch': 0.52}\n",
      "{'loss': 0.5893, 'grad_norm': 1.40625, 'learning_rate': 8.24945295404814e-05, 'epoch': 0.53}\n",
      "{'loss': 0.6587, 'grad_norm': 1.421875, 'learning_rate': 8.231218088986142e-05, 'epoch': 0.53}\n",
      "{'loss': 0.6208, 'grad_norm': 1.4140625, 'learning_rate': 8.212983223924143e-05, 'epoch': 0.54}\n",
      "{'loss': 0.6508, 'grad_norm': 1.3125, 'learning_rate': 8.194748358862144e-05, 'epoch': 0.54}\n",
      "{'loss': 0.6237, 'grad_norm': 1.0859375, 'learning_rate': 8.176513493800146e-05, 'epoch': 0.55}\n",
      "{'loss': 0.7443, 'grad_norm': 1.109375, 'learning_rate': 8.158278628738147e-05, 'epoch': 0.55}\n",
      "{'loss': 0.6227, 'grad_norm': 0.984375, 'learning_rate': 8.140043763676149e-05, 'epoch': 0.56}\n",
      "{'loss': 0.6181, 'grad_norm': 1.3203125, 'learning_rate': 8.12180889861415e-05, 'epoch': 0.56}\n",
      "{'loss': 0.5921, 'grad_norm': 0.859375, 'learning_rate': 8.103574033552152e-05, 'epoch': 0.57}\n",
      "{'loss': 0.5431, 'grad_norm': 1.0, 'learning_rate': 8.085339168490153e-05, 'epoch': 0.57}\n",
      "{'loss': 0.6325, 'grad_norm': 2.171875, 'learning_rate': 8.067104303428154e-05, 'epoch': 0.58}\n",
      "{'loss': 0.6283, 'grad_norm': 1.4921875, 'learning_rate': 8.048869438366157e-05, 'epoch': 0.59}\n",
      "{'loss': 0.6985, 'grad_norm': 1.3359375, 'learning_rate': 8.030634573304157e-05, 'epoch': 0.59}\n",
      "{'loss': 0.7015, 'grad_norm': 1.3984375, 'learning_rate': 8.01239970824216e-05, 'epoch': 0.6}\n",
      "{'loss': 0.6079, 'grad_norm': 1.3359375, 'learning_rate': 7.99416484318016e-05, 'epoch': 0.6}\n",
      "{'loss': 0.6011, 'grad_norm': 0.90625, 'learning_rate': 7.975929978118162e-05, 'epoch': 0.61}\n",
      "{'loss': 0.6239, 'grad_norm': 1.3359375, 'learning_rate': 7.957695113056164e-05, 'epoch': 0.61}\n",
      "{'loss': 0.559, 'grad_norm': 0.91015625, 'learning_rate': 7.939460247994165e-05, 'epoch': 0.62}\n",
      "{'loss': 0.6134, 'grad_norm': 1.2578125, 'learning_rate': 7.921225382932167e-05, 'epoch': 0.62}\n",
      "{'loss': 0.6098, 'grad_norm': 1.265625, 'learning_rate': 7.902990517870168e-05, 'epoch': 0.63}\n",
      "{'loss': 0.5271, 'grad_norm': 1.0546875, 'learning_rate': 7.88475565280817e-05, 'epoch': 0.63}\n",
      "{'loss': 0.5633, 'grad_norm': 1.140625, 'learning_rate': 7.866520787746171e-05, 'epoch': 0.64}\n",
      "{'loss': 0.6191, 'grad_norm': 1.265625, 'learning_rate': 7.848285922684172e-05, 'epoch': 0.65}\n",
      "{'loss': 0.546, 'grad_norm': 1.1875, 'learning_rate': 7.830051057622174e-05, 'epoch': 0.65}\n",
      "{'loss': 0.5895, 'grad_norm': 1.1796875, 'learning_rate': 7.811816192560175e-05, 'epoch': 0.66}\n",
      "{'loss': 0.6285, 'grad_norm': 0.83203125, 'learning_rate': 7.793581327498177e-05, 'epoch': 0.66}\n",
      "{'loss': 0.54, 'grad_norm': 1.3671875, 'learning_rate': 7.775346462436178e-05, 'epoch': 0.67}\n",
      "{'loss': 0.5294, 'grad_norm': 1.6328125, 'learning_rate': 7.757111597374179e-05, 'epoch': 0.67}\n",
      "{'loss': 0.5744, 'grad_norm': 1.0234375, 'learning_rate': 7.738876732312182e-05, 'epoch': 0.68}\n",
      "{'loss': 0.6477, 'grad_norm': 1.359375, 'learning_rate': 7.720641867250182e-05, 'epoch': 0.68}\n",
      "{'loss': 0.5963, 'grad_norm': 1.21875, 'learning_rate': 7.702407002188185e-05, 'epoch': 0.69}\n",
      "{'loss': 0.5108, 'grad_norm': 1.4296875, 'learning_rate': 7.684172137126186e-05, 'epoch': 0.69}\n",
      "{'loss': 0.5251, 'grad_norm': 1.2421875, 'learning_rate': 7.665937272064188e-05, 'epoch': 0.7}\n",
      "{'loss': 0.5182, 'grad_norm': 0.953125, 'learning_rate': 7.647702407002189e-05, 'epoch': 0.71}\n",
      "{'loss': 0.6523, 'grad_norm': 1.2265625, 'learning_rate': 7.62946754194019e-05, 'epoch': 0.71}\n",
      "{'loss': 0.5402, 'grad_norm': 1.046875, 'learning_rate': 7.611232676878192e-05, 'epoch': 0.72}\n",
      "{'loss': 0.6371, 'grad_norm': 1.3984375, 'learning_rate': 7.592997811816193e-05, 'epoch': 0.72}\n",
      "{'loss': 0.5241, 'grad_norm': 1.2109375, 'learning_rate': 7.574762946754195e-05, 'epoch': 0.73}\n",
      "{'loss': 0.5598, 'grad_norm': 1.078125, 'learning_rate': 7.556528081692196e-05, 'epoch': 0.73}\n",
      "{'loss': 0.61, 'grad_norm': 1.0625, 'learning_rate': 7.538293216630198e-05, 'epoch': 0.74}\n",
      "{'loss': 0.6664, 'grad_norm': 1.578125, 'learning_rate': 7.520058351568199e-05, 'epoch': 0.74}\n",
      "{'loss': 0.6075, 'grad_norm': 1.484375, 'learning_rate': 7.5018234865062e-05, 'epoch': 0.75}\n",
      "{'loss': 0.5581, 'grad_norm': 1.59375, 'learning_rate': 7.483588621444202e-05, 'epoch': 0.75}\n",
      "{'loss': 0.6435, 'grad_norm': 1.0859375, 'learning_rate': 7.465353756382203e-05, 'epoch': 0.76}\n",
      "{'loss': 0.5988, 'grad_norm': 1.546875, 'learning_rate': 7.447118891320206e-05, 'epoch': 0.77}\n",
      "{'loss': 0.6186, 'grad_norm': 1.4140625, 'learning_rate': 7.428884026258207e-05, 'epoch': 0.77}\n",
      "{'loss': 0.6355, 'grad_norm': 1.5546875, 'learning_rate': 7.410649161196207e-05, 'epoch': 0.78}\n",
      "{'loss': 0.6598, 'grad_norm': 1.078125, 'learning_rate': 7.39241429613421e-05, 'epoch': 0.78}\n",
      "{'loss': 0.698, 'grad_norm': 1.1171875, 'learning_rate': 7.37417943107221e-05, 'epoch': 0.79}\n",
      "{'loss': 0.6577, 'grad_norm': 1.0390625, 'learning_rate': 7.355944566010212e-05, 'epoch': 0.79}\n",
      "{'loss': 0.5993, 'grad_norm': 1.2421875, 'learning_rate': 7.337709700948214e-05, 'epoch': 0.8}\n",
      "{'loss': 0.5738, 'grad_norm': 1.5625, 'learning_rate': 7.319474835886215e-05, 'epoch': 0.8}\n",
      "{'loss': 0.6783, 'grad_norm': 1.46875, 'learning_rate': 7.301239970824216e-05, 'epoch': 0.81}\n",
      "{'loss': 0.5914, 'grad_norm': 1.03125, 'learning_rate': 7.283005105762218e-05, 'epoch': 0.82}\n",
      "{'loss': 0.5822, 'grad_norm': 1.015625, 'learning_rate': 7.264770240700219e-05, 'epoch': 0.82}\n",
      "{'loss': 0.6595, 'grad_norm': 1.328125, 'learning_rate': 7.24653537563822e-05, 'epoch': 0.83}\n",
      "{'loss': 0.5684, 'grad_norm': 0.9921875, 'learning_rate': 7.228300510576222e-05, 'epoch': 0.83}\n",
      "{'loss': 0.5149, 'grad_norm': 1.2734375, 'learning_rate': 7.210065645514223e-05, 'epoch': 0.84}\n",
      "{'loss': 0.6346, 'grad_norm': 1.3671875, 'learning_rate': 7.191830780452224e-05, 'epoch': 0.84}\n",
      "{'loss': 0.5994, 'grad_norm': 1.3046875, 'learning_rate': 7.173595915390226e-05, 'epoch': 0.85}\n",
      "{'loss': 0.6091, 'grad_norm': 1.3515625, 'learning_rate': 7.155361050328227e-05, 'epoch': 0.85}\n",
      "{'loss': 0.6087, 'grad_norm': 1.6484375, 'learning_rate': 7.137126185266229e-05, 'epoch': 0.86}\n",
      "{'loss': 0.6377, 'grad_norm': 1.2265625, 'learning_rate': 7.11889132020423e-05, 'epoch': 0.86}\n",
      "{'loss': 0.5285, 'grad_norm': 1.1953125, 'learning_rate': 7.100656455142232e-05, 'epoch': 0.87}\n",
      "{'loss': 0.4998, 'grad_norm': 1.125, 'learning_rate': 7.082421590080233e-05, 'epoch': 0.88}\n",
      "{'loss': 0.5354, 'grad_norm': 1.28125, 'learning_rate': 7.064186725018234e-05, 'epoch': 0.88}\n",
      "{'loss': 0.5792, 'grad_norm': 1.3828125, 'learning_rate': 7.045951859956237e-05, 'epoch': 0.89}\n",
      "{'loss': 0.5955, 'grad_norm': 1.34375, 'learning_rate': 7.027716994894238e-05, 'epoch': 0.89}\n",
      "{'loss': 0.5084, 'grad_norm': 1.65625, 'learning_rate': 7.00948212983224e-05, 'epoch': 0.9}\n",
      "{'loss': 0.5426, 'grad_norm': 1.5625, 'learning_rate': 6.991247264770241e-05, 'epoch': 0.9}\n",
      "{'loss': 0.5819, 'grad_norm': 0.98046875, 'learning_rate': 6.973012399708242e-05, 'epoch': 0.91}\n",
      "{'loss': 0.4821, 'grad_norm': 1.3359375, 'learning_rate': 6.954777534646244e-05, 'epoch': 0.91}\n",
      "{'loss': 0.5686, 'grad_norm': 0.94921875, 'learning_rate': 6.936542669584245e-05, 'epoch': 0.92}\n",
      "{'loss': 0.594, 'grad_norm': 1.375, 'learning_rate': 6.918307804522247e-05, 'epoch': 0.92}\n",
      "{'loss': 0.6042, 'grad_norm': 1.7265625, 'learning_rate': 6.900072939460248e-05, 'epoch': 0.93}\n",
      "{'loss': 0.6312, 'grad_norm': 0.9296875, 'learning_rate': 6.88183807439825e-05, 'epoch': 0.94}\n",
      "{'loss': 0.5932, 'grad_norm': 1.234375, 'learning_rate': 6.863603209336251e-05, 'epoch': 0.94}\n",
      "{'loss': 0.6699, 'grad_norm': 1.5390625, 'learning_rate': 6.845368344274252e-05, 'epoch': 0.95}\n",
      "{'loss': 0.5804, 'grad_norm': 1.4140625, 'learning_rate': 6.827133479212254e-05, 'epoch': 0.95}\n",
      "{'loss': 0.5849, 'grad_norm': 1.046875, 'learning_rate': 6.808898614150255e-05, 'epoch': 0.96}\n",
      "{'loss': 0.5845, 'grad_norm': 1.265625, 'learning_rate': 6.790663749088258e-05, 'epoch': 0.96}\n",
      "{'loss': 0.5363, 'grad_norm': 1.1796875, 'learning_rate': 6.772428884026258e-05, 'epoch': 0.97}\n",
      "{'loss': 0.6159, 'grad_norm': 1.4140625, 'learning_rate': 6.754194018964261e-05, 'epoch': 0.97}\n",
      "{'loss': 0.6107, 'grad_norm': 1.2890625, 'learning_rate': 6.735959153902262e-05, 'epoch': 0.98}\n",
      "{'loss': 0.6688, 'grad_norm': 1.9375, 'learning_rate': 6.717724288840263e-05, 'epoch': 0.98}\n",
      "{'loss': 0.5964, 'grad_norm': 1.3046875, 'learning_rate': 6.699489423778265e-05, 'epoch': 0.99}\n",
      "{'loss': 0.5641, 'grad_norm': 1.15625, 'learning_rate': 6.681254558716266e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/face_craft_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6427, 'grad_norm': 1.3046875, 'learning_rate': 6.663019693654268e-05, 'epoch': 1.0}\n",
      "{'loss': 0.5619, 'grad_norm': 1.625, 'learning_rate': 6.644784828592269e-05, 'epoch': 1.01}\n",
      "{'loss': 0.5373, 'grad_norm': 1.171875, 'learning_rate': 6.62654996353027e-05, 'epoch': 1.01}\n",
      "{'loss': 0.613, 'grad_norm': 1.296875, 'learning_rate': 6.608315098468272e-05, 'epoch': 1.02}\n",
      "{'loss': 0.5004, 'grad_norm': 1.5078125, 'learning_rate': 6.590080233406273e-05, 'epoch': 1.02}\n",
      "{'loss': 0.4756, 'grad_norm': 1.3046875, 'learning_rate': 6.571845368344275e-05, 'epoch': 1.03}\n",
      "{'loss': 0.5488, 'grad_norm': 1.3203125, 'learning_rate': 6.553610503282276e-05, 'epoch': 1.03}\n",
      "{'loss': 0.582, 'grad_norm': 1.03125, 'learning_rate': 6.535375638220278e-05, 'epoch': 1.04}\n",
      "{'loss': 0.5704, 'grad_norm': 1.65625, 'learning_rate': 6.51714077315828e-05, 'epoch': 1.04}\n",
      "{'loss': 0.59, 'grad_norm': 1.0234375, 'learning_rate': 6.49890590809628e-05, 'epoch': 1.05}\n",
      "{'loss': 0.6494, 'grad_norm': 1.1171875, 'learning_rate': 6.480671043034283e-05, 'epoch': 1.06}\n",
      "{'loss': 0.5113, 'grad_norm': 1.5078125, 'learning_rate': 6.462436177972283e-05, 'epoch': 1.06}\n",
      "{'loss': 0.5674, 'grad_norm': 1.4296875, 'learning_rate': 6.444201312910286e-05, 'epoch': 1.07}\n",
      "{'loss': 0.5349, 'grad_norm': 1.328125, 'learning_rate': 6.425966447848287e-05, 'epoch': 1.07}\n",
      "{'loss': 0.5348, 'grad_norm': 1.171875, 'learning_rate': 6.407731582786288e-05, 'epoch': 1.08}\n",
      "{'loss': 0.5953, 'grad_norm': 1.2578125, 'learning_rate': 6.38949671772429e-05, 'epoch': 1.08}\n",
      "{'loss': 0.5589, 'grad_norm': 1.5625, 'learning_rate': 6.371261852662291e-05, 'epoch': 1.09}\n",
      "{'loss': 0.4484, 'grad_norm': 1.2734375, 'learning_rate': 6.353026987600293e-05, 'epoch': 1.09}\n",
      "{'loss': 0.4839, 'grad_norm': 1.3515625, 'learning_rate': 6.334792122538294e-05, 'epoch': 1.1}\n",
      "{'loss': 0.5414, 'grad_norm': 1.4453125, 'learning_rate': 6.316557257476295e-05, 'epoch': 1.1}\n",
      "{'loss': 0.5869, 'grad_norm': 1.7578125, 'learning_rate': 6.298322392414297e-05, 'epoch': 1.11}\n",
      "{'loss': 0.5266, 'grad_norm': 1.5390625, 'learning_rate': 6.280087527352298e-05, 'epoch': 1.12}\n",
      "{'loss': 0.5309, 'grad_norm': 1.3046875, 'learning_rate': 6.261852662290299e-05, 'epoch': 1.12}\n",
      "{'loss': 0.5843, 'grad_norm': 1.703125, 'learning_rate': 6.243617797228301e-05, 'epoch': 1.13}\n",
      "{'loss': 0.5126, 'grad_norm': 0.86328125, 'learning_rate': 6.225382932166302e-05, 'epoch': 1.13}\n",
      "{'loss': 0.6047, 'grad_norm': 1.265625, 'learning_rate': 6.207148067104303e-05, 'epoch': 1.14}\n",
      "{'loss': 0.5412, 'grad_norm': 1.1171875, 'learning_rate': 6.188913202042305e-05, 'epoch': 1.14}\n",
      "{'loss': 0.5724, 'grad_norm': 1.453125, 'learning_rate': 6.170678336980306e-05, 'epoch': 1.15}\n",
      "{'loss': 0.4711, 'grad_norm': 1.703125, 'learning_rate': 6.152443471918307e-05, 'epoch': 1.15}\n",
      "{'loss': 0.6288, 'grad_norm': 1.421875, 'learning_rate': 6.13420860685631e-05, 'epoch': 1.16}\n",
      "{'loss': 0.5464, 'grad_norm': 2.0625, 'learning_rate': 6.11597374179431e-05, 'epoch': 1.17}\n",
      "{'loss': 0.5273, 'grad_norm': 1.9296875, 'learning_rate': 6.097738876732313e-05, 'epoch': 1.17}\n",
      "{'loss': 0.686, 'grad_norm': 1.3671875, 'learning_rate': 6.079504011670314e-05, 'epoch': 1.18}\n",
      "{'loss': 0.5848, 'grad_norm': 1.3828125, 'learning_rate': 6.061269146608315e-05, 'epoch': 1.18}\n",
      "{'loss': 0.5376, 'grad_norm': 1.9609375, 'learning_rate': 6.0430342815463173e-05, 'epoch': 1.19}\n",
      "{'loss': 0.5227, 'grad_norm': 1.7421875, 'learning_rate': 6.024799416484318e-05, 'epoch': 1.19}\n",
      "{'loss': 0.5144, 'grad_norm': 1.0, 'learning_rate': 6.00656455142232e-05, 'epoch': 1.2}\n",
      "{'loss': 0.5554, 'grad_norm': 1.140625, 'learning_rate': 5.988329686360321e-05, 'epoch': 1.2}\n",
      "{'loss': 0.6051, 'grad_norm': 1.78125, 'learning_rate': 5.970094821298323e-05, 'epoch': 1.21}\n",
      "{'loss': 0.6113, 'grad_norm': 1.6796875, 'learning_rate': 5.951859956236324e-05, 'epoch': 1.21}\n",
      "{'loss': 0.5637, 'grad_norm': 1.484375, 'learning_rate': 5.933625091174325e-05, 'epoch': 1.22}\n",
      "{'loss': 0.5611, 'grad_norm': 1.6015625, 'learning_rate': 5.915390226112327e-05, 'epoch': 1.23}\n",
      "{'loss': 0.5181, 'grad_norm': 1.6796875, 'learning_rate': 5.897155361050328e-05, 'epoch': 1.23}\n",
      "{'loss': 0.5423, 'grad_norm': 1.578125, 'learning_rate': 5.87892049598833e-05, 'epoch': 1.24}\n",
      "{'loss': 0.5553, 'grad_norm': 1.3203125, 'learning_rate': 5.860685630926331e-05, 'epoch': 1.24}\n",
      "{'loss': 0.5348, 'grad_norm': 1.484375, 'learning_rate': 5.842450765864332e-05, 'epoch': 1.25}\n",
      "{'loss': 0.531, 'grad_norm': 1.4609375, 'learning_rate': 5.8242159008023344e-05, 'epoch': 1.25}\n",
      "{'loss': 0.5356, 'grad_norm': 1.5234375, 'learning_rate': 5.805981035740335e-05, 'epoch': 1.26}\n",
      "{'loss': 0.5951, 'grad_norm': 1.0390625, 'learning_rate': 5.7877461706783376e-05, 'epoch': 1.26}\n",
      "{'loss': 0.5422, 'grad_norm': 1.546875, 'learning_rate': 5.7695113056163385e-05, 'epoch': 1.27}\n",
      "{'loss': 0.5667, 'grad_norm': 1.546875, 'learning_rate': 5.751276440554341e-05, 'epoch': 1.27}\n",
      "{'loss': 0.5689, 'grad_norm': 1.6171875, 'learning_rate': 5.733041575492342e-05, 'epoch': 1.28}\n",
      "{'loss': 0.5866, 'grad_norm': 2.09375, 'learning_rate': 5.7148067104303426e-05, 'epoch': 1.29}\n",
      "{'loss': 0.5484, 'grad_norm': 1.234375, 'learning_rate': 5.696571845368345e-05, 'epoch': 1.29}\n",
      "{'loss': 0.4714, 'grad_norm': 1.5625, 'learning_rate': 5.678336980306346e-05, 'epoch': 1.3}\n",
      "{'loss': 0.4626, 'grad_norm': 1.296875, 'learning_rate': 5.660102115244348e-05, 'epoch': 1.3}\n",
      "{'loss': 0.4881, 'grad_norm': 1.4296875, 'learning_rate': 5.641867250182349e-05, 'epoch': 1.31}\n",
      "{'loss': 0.5027, 'grad_norm': 1.234375, 'learning_rate': 5.62363238512035e-05, 'epoch': 1.31}\n",
      "{'loss': 0.522, 'grad_norm': 1.15625, 'learning_rate': 5.605397520058352e-05, 'epoch': 1.32}\n",
      "{'loss': 0.538, 'grad_norm': 1.4609375, 'learning_rate': 5.587162654996353e-05, 'epoch': 1.32}\n",
      "{'loss': 0.4696, 'grad_norm': 1.296875, 'learning_rate': 5.568927789934355e-05, 'epoch': 1.33}\n",
      "{'loss': 0.5386, 'grad_norm': 1.765625, 'learning_rate': 5.550692924872356e-05, 'epoch': 1.33}\n",
      "{'loss': 0.5882, 'grad_norm': 2.078125, 'learning_rate': 5.532458059810358e-05, 'epoch': 1.34}\n",
      "{'loss': 0.5881, 'grad_norm': 1.4765625, 'learning_rate': 5.5142231947483594e-05, 'epoch': 1.35}\n",
      "{'loss': 0.6046, 'grad_norm': 1.828125, 'learning_rate': 5.4959883296863603e-05, 'epoch': 1.35}\n",
      "{'loss': 0.697, 'grad_norm': 1.65625, 'learning_rate': 5.477753464624362e-05, 'epoch': 1.36}\n",
      "{'loss': 0.5593, 'grad_norm': 1.1171875, 'learning_rate': 5.4595185995623635e-05, 'epoch': 1.36}\n",
      "{'loss': 0.5571, 'grad_norm': 1.53125, 'learning_rate': 5.441283734500365e-05, 'epoch': 1.37}\n",
      "{'loss': 0.5102, 'grad_norm': 1.515625, 'learning_rate': 5.423048869438366e-05, 'epoch': 1.37}\n",
      "{'loss': 0.5814, 'grad_norm': 1.703125, 'learning_rate': 5.404814004376368e-05, 'epoch': 1.38}\n",
      "{'loss': 0.5575, 'grad_norm': 1.8203125, 'learning_rate': 5.386579139314369e-05, 'epoch': 1.38}\n",
      "{'loss': 0.5874, 'grad_norm': 1.375, 'learning_rate': 5.36834427425237e-05, 'epoch': 1.39}\n",
      "{'loss': 0.5187, 'grad_norm': 1.1171875, 'learning_rate': 5.3501094091903724e-05, 'epoch': 1.39}\n",
      "{'loss': 0.5051, 'grad_norm': 1.796875, 'learning_rate': 5.331874544128373e-05, 'epoch': 1.4}\n",
      "{'loss': 0.5742, 'grad_norm': 1.875, 'learning_rate': 5.3136396790663756e-05, 'epoch': 1.41}\n",
      "{'loss': 0.5874, 'grad_norm': 1.59375, 'learning_rate': 5.2954048140043765e-05, 'epoch': 1.41}\n",
      "{'loss': 0.5063, 'grad_norm': 1.6015625, 'learning_rate': 5.2771699489423774e-05, 'epoch': 1.42}\n",
      "{'loss': 0.4559, 'grad_norm': 1.2421875, 'learning_rate': 5.25893508388038e-05, 'epoch': 1.42}\n",
      "{'loss': 0.5881, 'grad_norm': 1.2265625, 'learning_rate': 5.2407002188183806e-05, 'epoch': 1.43}\n",
      "{'loss': 0.5575, 'grad_norm': 1.75, 'learning_rate': 5.222465353756383e-05, 'epoch': 1.43}\n",
      "{'loss': 0.5879, 'grad_norm': 1.3046875, 'learning_rate': 5.204230488694384e-05, 'epoch': 1.44}\n",
      "{'loss': 0.5428, 'grad_norm': 0.94140625, 'learning_rate': 5.185995623632386e-05, 'epoch': 1.44}\n",
      "{'loss': 0.5434, 'grad_norm': 2.1875, 'learning_rate': 5.167760758570387e-05, 'epoch': 1.45}\n",
      "{'loss': 0.5688, 'grad_norm': 1.8515625, 'learning_rate': 5.149525893508388e-05, 'epoch': 1.46}\n",
      "{'loss': 0.5182, 'grad_norm': 1.359375, 'learning_rate': 5.13129102844639e-05, 'epoch': 1.46}\n",
      "{'loss': 0.5254, 'grad_norm': 1.5546875, 'learning_rate': 5.113056163384391e-05, 'epoch': 1.47}\n",
      "{'loss': 0.5476, 'grad_norm': 1.28125, 'learning_rate': 5.094821298322393e-05, 'epoch': 1.47}\n",
      "{'loss': 0.4831, 'grad_norm': 1.59375, 'learning_rate': 5.076586433260394e-05, 'epoch': 1.48}\n",
      "{'loss': 0.5014, 'grad_norm': 1.6640625, 'learning_rate': 5.058351568198395e-05, 'epoch': 1.48}\n",
      "{'loss': 0.5987, 'grad_norm': 1.71875, 'learning_rate': 5.0401167031363974e-05, 'epoch': 1.49}\n",
      "{'loss': 0.5075, 'grad_norm': 1.8046875, 'learning_rate': 5.021881838074398e-05, 'epoch': 1.49}\n",
      "{'loss': 0.483, 'grad_norm': 1.609375, 'learning_rate': 5.0036469730124006e-05, 'epoch': 1.5}\n",
      "{'loss': 0.4471, 'grad_norm': 1.015625, 'learning_rate': 4.9854121079504015e-05, 'epoch': 1.5}\n",
      "{'loss': 0.4951, 'grad_norm': 1.484375, 'learning_rate': 4.967177242888403e-05, 'epoch': 1.51}\n",
      "{'loss': 0.5377, 'grad_norm': 1.578125, 'learning_rate': 4.948942377826404e-05, 'epoch': 1.52}\n",
      "{'loss': 0.5958, 'grad_norm': 1.21875, 'learning_rate': 4.9307075127644056e-05, 'epoch': 1.52}\n",
      "{'loss': 0.5281, 'grad_norm': 1.359375, 'learning_rate': 4.912472647702407e-05, 'epoch': 1.53}\n",
      "{'loss': 0.5886, 'grad_norm': 1.265625, 'learning_rate': 4.894237782640408e-05, 'epoch': 1.53}\n",
      "{'loss': 0.5747, 'grad_norm': 1.796875, 'learning_rate': 4.87600291757841e-05, 'epoch': 1.54}\n",
      "{'loss': 0.5647, 'grad_norm': 1.703125, 'learning_rate': 4.857768052516411e-05, 'epoch': 1.54}\n",
      "{'loss': 0.632, 'grad_norm': 1.625, 'learning_rate': 4.839533187454413e-05, 'epoch': 1.55}\n",
      "{'loss': 0.5329, 'grad_norm': 1.8515625, 'learning_rate': 4.8212983223924145e-05, 'epoch': 1.55}\n",
      "{'loss': 0.5607, 'grad_norm': 1.5703125, 'learning_rate': 4.803063457330416e-05, 'epoch': 1.56}\n",
      "{'loss': 0.4946, 'grad_norm': 1.6328125, 'learning_rate': 4.784828592268417e-05, 'epoch': 1.56}\n",
      "{'loss': 0.493, 'grad_norm': 1.7578125, 'learning_rate': 4.7665937272064186e-05, 'epoch': 1.57}\n",
      "{'loss': 0.5579, 'grad_norm': 1.84375, 'learning_rate': 4.74835886214442e-05, 'epoch': 1.58}\n",
      "{'loss': 0.5003, 'grad_norm': 0.99609375, 'learning_rate': 4.730123997082422e-05, 'epoch': 1.58}\n",
      "{'loss': 0.5254, 'grad_norm': 1.3203125, 'learning_rate': 4.7118891320204234e-05, 'epoch': 1.59}\n",
      "{'loss': 0.5974, 'grad_norm': 1.8671875, 'learning_rate': 4.693654266958425e-05, 'epoch': 1.59}\n",
      "{'loss': 0.6034, 'grad_norm': 1.4609375, 'learning_rate': 4.6754194018964265e-05, 'epoch': 1.6}\n",
      "{'loss': 0.5449, 'grad_norm': 1.4296875, 'learning_rate': 4.6571845368344274e-05, 'epoch': 1.6}\n",
      "{'loss': 0.5511, 'grad_norm': 1.4765625, 'learning_rate': 4.638949671772429e-05, 'epoch': 1.61}\n",
      "{'loss': 0.4876, 'grad_norm': 1.5859375, 'learning_rate': 4.6207148067104306e-05, 'epoch': 1.61}\n",
      "{'loss': 0.588, 'grad_norm': 2.15625, 'learning_rate': 4.602479941648432e-05, 'epoch': 1.62}\n",
      "{'loss': 0.5614, 'grad_norm': 2.390625, 'learning_rate': 4.584245076586434e-05, 'epoch': 1.62}\n",
      "{'loss': 0.5786, 'grad_norm': 2.25, 'learning_rate': 4.5660102115244354e-05, 'epoch': 1.63}\n",
      "{'loss': 0.5721, 'grad_norm': 2.046875, 'learning_rate': 4.547775346462436e-05, 'epoch': 1.64}\n",
      "{'loss': 0.5554, 'grad_norm': 1.5546875, 'learning_rate': 4.529540481400438e-05, 'epoch': 1.64}\n",
      "{'loss': 0.5122, 'grad_norm': 1.015625, 'learning_rate': 4.5113056163384395e-05, 'epoch': 1.65}\n",
      "{'loss': 0.6498, 'grad_norm': 1.859375, 'learning_rate': 4.493070751276441e-05, 'epoch': 1.65}\n",
      "{'loss': 0.4698, 'grad_norm': 1.484375, 'learning_rate': 4.474835886214443e-05, 'epoch': 1.66}\n",
      "{'loss': 0.5054, 'grad_norm': 0.97265625, 'learning_rate': 4.4566010211524436e-05, 'epoch': 1.66}\n",
      "{'loss': 0.5632, 'grad_norm': 1.765625, 'learning_rate': 4.438366156090445e-05, 'epoch': 1.67}\n",
      "{'loss': 0.5393, 'grad_norm': 1.3671875, 'learning_rate': 4.420131291028447e-05, 'epoch': 1.67}\n",
      "{'loss': 0.5359, 'grad_norm': 1.9375, 'learning_rate': 4.401896425966448e-05, 'epoch': 1.68}\n",
      "{'loss': 0.5651, 'grad_norm': 2.015625, 'learning_rate': 4.383661560904449e-05, 'epoch': 1.68}\n",
      "{'loss': 0.5999, 'grad_norm': 1.4609375, 'learning_rate': 4.365426695842451e-05, 'epoch': 1.69}\n",
      "{'loss': 0.5643, 'grad_norm': 1.4453125, 'learning_rate': 4.3471918307804525e-05, 'epoch': 1.7}\n",
      "{'loss': 0.52, 'grad_norm': 1.6875, 'learning_rate': 4.3289569657184534e-05, 'epoch': 1.7}\n",
      "{'loss': 0.5314, 'grad_norm': 1.25, 'learning_rate': 4.310722100656455e-05, 'epoch': 1.71}\n",
      "{'loss': 0.4653, 'grad_norm': 1.0546875, 'learning_rate': 4.2924872355944566e-05, 'epoch': 1.71}\n",
      "{'loss': 0.5324, 'grad_norm': 2.328125, 'learning_rate': 4.274252370532458e-05, 'epoch': 1.72}\n",
      "{'loss': 0.572, 'grad_norm': 1.359375, 'learning_rate': 4.25601750547046e-05, 'epoch': 1.72}\n",
      "{'loss': 0.5139, 'grad_norm': 1.53125, 'learning_rate': 4.237782640408461e-05, 'epoch': 1.73}\n",
      "{'loss': 0.4944, 'grad_norm': 2.0, 'learning_rate': 4.219547775346462e-05, 'epoch': 1.73}\n",
      "{'loss': 0.5575, 'grad_norm': 2.0, 'learning_rate': 4.201312910284464e-05, 'epoch': 1.74}\n",
      "{'loss': 0.5046, 'grad_norm': 1.3828125, 'learning_rate': 4.1830780452224654e-05, 'epoch': 1.74}\n",
      "{'loss': 0.4647, 'grad_norm': 1.2890625, 'learning_rate': 4.164843180160467e-05, 'epoch': 1.75}\n",
      "{'loss': 0.5442, 'grad_norm': 1.8359375, 'learning_rate': 4.1466083150984686e-05, 'epoch': 1.76}\n",
      "{'loss': 0.607, 'grad_norm': 2.125, 'learning_rate': 4.12837345003647e-05, 'epoch': 1.76}\n",
      "{'loss': 0.6139, 'grad_norm': 1.46875, 'learning_rate': 4.110138584974471e-05, 'epoch': 1.77}\n",
      "{'loss': 0.4922, 'grad_norm': 1.75, 'learning_rate': 4.091903719912473e-05, 'epoch': 1.77}\n",
      "{'loss': 0.5406, 'grad_norm': 1.3984375, 'learning_rate': 4.073668854850474e-05, 'epoch': 1.78}\n",
      "{'loss': 0.5373, 'grad_norm': 1.6328125, 'learning_rate': 4.055433989788476e-05, 'epoch': 1.78}\n",
      "{'loss': 0.5238, 'grad_norm': 1.9921875, 'learning_rate': 4.0371991247264775e-05, 'epoch': 1.79}\n",
      "{'loss': 0.5227, 'grad_norm': 1.6640625, 'learning_rate': 4.018964259664479e-05, 'epoch': 1.79}\n",
      "{'loss': 0.4959, 'grad_norm': 1.59375, 'learning_rate': 4.00072939460248e-05, 'epoch': 1.8}\n",
      "{'loss': 0.5363, 'grad_norm': 1.78125, 'learning_rate': 3.9824945295404816e-05, 'epoch': 1.81}\n",
      "{'loss': 0.5607, 'grad_norm': 1.4140625, 'learning_rate': 3.964259664478483e-05, 'epoch': 1.81}\n",
      "{'loss': 0.5173, 'grad_norm': 1.84375, 'learning_rate': 3.946024799416485e-05, 'epoch': 1.82}\n",
      "{'loss': 0.5472, 'grad_norm': 1.75, 'learning_rate': 3.9277899343544864e-05, 'epoch': 1.82}\n",
      "{'loss': 0.477, 'grad_norm': 1.328125, 'learning_rate': 3.909555069292487e-05, 'epoch': 1.83}\n",
      "{'loss': 0.5049, 'grad_norm': 1.4609375, 'learning_rate': 3.891320204230489e-05, 'epoch': 1.83}\n",
      "{'loss': 0.5321, 'grad_norm': 1.609375, 'learning_rate': 3.8730853391684905e-05, 'epoch': 1.84}\n",
      "{'loss': 0.4963, 'grad_norm': 1.6171875, 'learning_rate': 3.8548504741064914e-05, 'epoch': 1.84}\n",
      "{'loss': 0.5052, 'grad_norm': 1.53125, 'learning_rate': 3.836615609044493e-05, 'epoch': 1.85}\n",
      "{'loss': 0.5255, 'grad_norm': 1.59375, 'learning_rate': 3.8183807439824946e-05, 'epoch': 1.85}\n",
      "{'loss': 0.5147, 'grad_norm': 2.171875, 'learning_rate': 3.800145878920496e-05, 'epoch': 1.86}\n",
      "{'loss': 0.4478, 'grad_norm': 1.9140625, 'learning_rate': 3.781911013858498e-05, 'epoch': 1.87}\n",
      "{'loss': 0.505, 'grad_norm': 1.6796875, 'learning_rate': 3.7636761487964986e-05, 'epoch': 1.87}\n",
      "{'loss': 0.4954, 'grad_norm': 1.21875, 'learning_rate': 3.7454412837345e-05, 'epoch': 1.88}\n",
      "{'loss': 0.5434, 'grad_norm': 1.671875, 'learning_rate': 3.727206418672502e-05, 'epoch': 1.88}\n",
      "{'loss': 0.4807, 'grad_norm': 1.5703125, 'learning_rate': 3.7089715536105034e-05, 'epoch': 1.89}\n",
      "{'loss': 0.5119, 'grad_norm': 2.84375, 'learning_rate': 3.690736688548505e-05, 'epoch': 1.89}\n",
      "{'loss': 0.5547, 'grad_norm': 2.390625, 'learning_rate': 3.6725018234865066e-05, 'epoch': 1.9}\n",
      "{'loss': 0.596, 'grad_norm': 2.421875, 'learning_rate': 3.6542669584245075e-05, 'epoch': 1.9}\n",
      "{'loss': 0.4971, 'grad_norm': 2.171875, 'learning_rate': 3.636032093362509e-05, 'epoch': 1.91}\n",
      "{'loss': 0.547, 'grad_norm': 1.1796875, 'learning_rate': 3.617797228300511e-05, 'epoch': 1.91}\n",
      "{'loss': 0.5075, 'grad_norm': 1.4375, 'learning_rate': 3.599562363238512e-05, 'epoch': 1.92}\n",
      "{'loss': 0.4967, 'grad_norm': 1.6953125, 'learning_rate': 3.581327498176514e-05, 'epoch': 1.93}\n",
      "{'loss': 0.5092, 'grad_norm': 1.875, 'learning_rate': 3.5630926331145155e-05, 'epoch': 1.93}\n",
      "{'loss': 0.504, 'grad_norm': 2.078125, 'learning_rate': 3.5448577680525164e-05, 'epoch': 1.94}\n",
      "{'loss': 0.502, 'grad_norm': 1.546875, 'learning_rate': 3.526622902990518e-05, 'epoch': 1.94}\n",
      "{'loss': 0.5344, 'grad_norm': 1.6875, 'learning_rate': 3.5083880379285196e-05, 'epoch': 1.95}\n",
      "{'loss': 0.5117, 'grad_norm': 2.171875, 'learning_rate': 3.490153172866521e-05, 'epoch': 1.95}\n",
      "{'loss': 0.6283, 'grad_norm': 1.7421875, 'learning_rate': 3.471918307804523e-05, 'epoch': 1.96}\n",
      "{'loss': 0.6026, 'grad_norm': 2.03125, 'learning_rate': 3.4536834427425243e-05, 'epoch': 1.96}\n",
      "{'loss': 0.4826, 'grad_norm': 1.875, 'learning_rate': 3.435448577680525e-05, 'epoch': 1.97}\n",
      "{'loss': 0.5265, 'grad_norm': 1.65625, 'learning_rate': 3.417213712618527e-05, 'epoch': 1.97}\n",
      "{'loss': 0.5687, 'grad_norm': 1.65625, 'learning_rate': 3.3989788475565284e-05, 'epoch': 1.98}\n",
      "{'loss': 0.5123, 'grad_norm': 2.359375, 'learning_rate': 3.38074398249453e-05, 'epoch': 1.99}\n",
      "{'loss': 0.4742, 'grad_norm': 1.765625, 'learning_rate': 3.362509117432531e-05, 'epoch': 1.99}\n",
      "{'loss': 0.5775, 'grad_norm': 1.3984375, 'learning_rate': 3.3442742523705325e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/face_craft_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6181, 'grad_norm': 1.375, 'learning_rate': 3.326039387308534e-05, 'epoch': 2.0}\n",
      "{'loss': 0.5152, 'grad_norm': 1.9765625, 'learning_rate': 3.307804522246535e-05, 'epoch': 2.01}\n",
      "{'loss': 0.5035, 'grad_norm': 1.875, 'learning_rate': 3.2895696571845366e-05, 'epoch': 2.01}\n",
      "{'loss': 0.5434, 'grad_norm': 2.609375, 'learning_rate': 3.271334792122538e-05, 'epoch': 2.02}\n",
      "{'loss': 0.5408, 'grad_norm': 2.21875, 'learning_rate': 3.25309992706054e-05, 'epoch': 2.02}\n",
      "{'loss': 0.4811, 'grad_norm': 1.2890625, 'learning_rate': 3.2348650619985414e-05, 'epoch': 2.03}\n",
      "{'loss': 0.5692, 'grad_norm': 1.28125, 'learning_rate': 3.216630196936542e-05, 'epoch': 2.03}\n",
      "{'loss': 0.4645, 'grad_norm': 1.734375, 'learning_rate': 3.198395331874544e-05, 'epoch': 2.04}\n",
      "{'loss': 0.5239, 'grad_norm': 2.28125, 'learning_rate': 3.1801604668125455e-05, 'epoch': 2.05}\n",
      "{'loss': 0.4693, 'grad_norm': 1.8828125, 'learning_rate': 3.161925601750547e-05, 'epoch': 2.05}\n",
      "{'loss': 0.4734, 'grad_norm': 2.671875, 'learning_rate': 3.143690736688549e-05, 'epoch': 2.06}\n",
      "{'loss': 0.4476, 'grad_norm': 2.296875, 'learning_rate': 3.12545587162655e-05, 'epoch': 2.06}\n",
      "{'loss': 0.5226, 'grad_norm': 1.84375, 'learning_rate': 3.107221006564552e-05, 'epoch': 2.07}\n",
      "{'loss': 0.4686, 'grad_norm': 2.03125, 'learning_rate': 3.088986141502553e-05, 'epoch': 2.07}\n",
      "{'loss': 0.4792, 'grad_norm': 1.9140625, 'learning_rate': 3.0707512764405544e-05, 'epoch': 2.08}\n",
      "{'loss': 0.4594, 'grad_norm': 1.859375, 'learning_rate': 3.052516411378556e-05, 'epoch': 2.08}\n",
      "{'loss': 0.4624, 'grad_norm': 1.2890625, 'learning_rate': 3.0342815463165576e-05, 'epoch': 2.09}\n",
      "{'loss': 0.573, 'grad_norm': 2.359375, 'learning_rate': 3.016046681254559e-05, 'epoch': 2.1}\n",
      "{'loss': 0.5266, 'grad_norm': 1.390625, 'learning_rate': 2.9978118161925607e-05, 'epoch': 2.1}\n",
      "{'loss': 0.527, 'grad_norm': 2.0625, 'learning_rate': 2.9795769511305617e-05, 'epoch': 2.11}\n",
      "{'loss': 0.4667, 'grad_norm': 2.34375, 'learning_rate': 2.9613420860685632e-05, 'epoch': 2.11}\n",
      "{'loss': 0.4782, 'grad_norm': 2.125, 'learning_rate': 2.9431072210065645e-05, 'epoch': 2.12}\n",
      "{'loss': 0.503, 'grad_norm': 2.125, 'learning_rate': 2.924872355944566e-05, 'epoch': 2.12}\n",
      "{'loss': 0.5005, 'grad_norm': 2.578125, 'learning_rate': 2.9066374908825677e-05, 'epoch': 2.13}\n",
      "{'loss': 0.4575, 'grad_norm': 2.421875, 'learning_rate': 2.8884026258205693e-05, 'epoch': 2.13}\n",
      "{'loss': 0.5252, 'grad_norm': 1.9375, 'learning_rate': 2.8701677607585702e-05, 'epoch': 2.14}\n",
      "{'loss': 0.5258, 'grad_norm': 1.25, 'learning_rate': 2.8519328956965718e-05, 'epoch': 2.14}\n",
      "{'loss': 0.5013, 'grad_norm': 1.6796875, 'learning_rate': 2.8336980306345734e-05, 'epoch': 2.15}\n",
      "{'loss': 0.5189, 'grad_norm': 2.234375, 'learning_rate': 2.815463165572575e-05, 'epoch': 2.16}\n",
      "{'loss': 0.4839, 'grad_norm': 1.0234375, 'learning_rate': 2.7972283005105766e-05, 'epoch': 2.16}\n",
      "{'loss': 0.5834, 'grad_norm': 1.9375, 'learning_rate': 2.778993435448578e-05, 'epoch': 2.17}\n",
      "{'loss': 0.5501, 'grad_norm': 3.203125, 'learning_rate': 2.760758570386579e-05, 'epoch': 2.17}\n",
      "{'loss': 0.615, 'grad_norm': 1.7734375, 'learning_rate': 2.7425237053245806e-05, 'epoch': 2.18}\n",
      "{'loss': 0.5291, 'grad_norm': 1.328125, 'learning_rate': 2.7242888402625822e-05, 'epoch': 2.18}\n",
      "{'loss': 0.4843, 'grad_norm': 1.2734375, 'learning_rate': 2.706053975200584e-05, 'epoch': 2.19}\n",
      "{'loss': 0.5567, 'grad_norm': 1.875, 'learning_rate': 2.687819110138585e-05, 'epoch': 2.19}\n",
      "{'loss': 0.4843, 'grad_norm': 1.5, 'learning_rate': 2.6695842450765867e-05, 'epoch': 2.2}\n",
      "{'loss': 0.4744, 'grad_norm': 2.078125, 'learning_rate': 2.651349380014588e-05, 'epoch': 2.2}\n",
      "{'loss': 0.5333, 'grad_norm': 2.046875, 'learning_rate': 2.6331145149525892e-05, 'epoch': 2.21}\n",
      "{'loss': 0.5206, 'grad_norm': 2.125, 'learning_rate': 2.6148796498905908e-05, 'epoch': 2.22}\n",
      "{'loss': 0.506, 'grad_norm': 1.5703125, 'learning_rate': 2.5966447848285924e-05, 'epoch': 2.22}\n",
      "{'loss': 0.5187, 'grad_norm': 1.65625, 'learning_rate': 2.578409919766594e-05, 'epoch': 2.23}\n",
      "{'loss': 0.4458, 'grad_norm': 1.3046875, 'learning_rate': 2.5601750547045955e-05, 'epoch': 2.23}\n",
      "{'loss': 0.4658, 'grad_norm': 1.671875, 'learning_rate': 2.5419401896425965e-05, 'epoch': 2.24}\n",
      "{'loss': 0.5167, 'grad_norm': 2.484375, 'learning_rate': 2.523705324580598e-05, 'epoch': 2.24}\n",
      "{'loss': 0.5499, 'grad_norm': 1.75, 'learning_rate': 2.5054704595185996e-05, 'epoch': 2.25}\n",
      "{'loss': 0.568, 'grad_norm': 1.953125, 'learning_rate': 2.4872355944566012e-05, 'epoch': 2.25}\n",
      "{'loss': 0.5216, 'grad_norm': 2.296875, 'learning_rate': 2.4690007293946028e-05, 'epoch': 2.26}\n",
      "{'loss': 0.5532, 'grad_norm': 2.484375, 'learning_rate': 2.450765864332604e-05, 'epoch': 2.26}\n",
      "{'loss': 0.5531, 'grad_norm': 1.65625, 'learning_rate': 2.4325309992706057e-05, 'epoch': 2.27}\n",
      "{'loss': 0.5063, 'grad_norm': 1.8671875, 'learning_rate': 2.414296134208607e-05, 'epoch': 2.28}\n",
      "{'loss': 0.4993, 'grad_norm': 1.9140625, 'learning_rate': 2.3960612691466082e-05, 'epoch': 2.28}\n",
      "{'loss': 0.584, 'grad_norm': 2.03125, 'learning_rate': 2.3778264040846098e-05, 'epoch': 2.29}\n",
      "{'loss': 0.4953, 'grad_norm': 1.1953125, 'learning_rate': 2.3595915390226114e-05, 'epoch': 2.29}\n",
      "{'loss': 0.5208, 'grad_norm': 2.515625, 'learning_rate': 2.3413566739606126e-05, 'epoch': 2.3}\n",
      "{'loss': 0.5222, 'grad_norm': 1.0546875, 'learning_rate': 2.3231218088986142e-05, 'epoch': 2.3}\n",
      "{'loss': 0.4863, 'grad_norm': 1.890625, 'learning_rate': 2.3048869438366158e-05, 'epoch': 2.31}\n",
      "{'loss': 0.4876, 'grad_norm': 1.5, 'learning_rate': 2.286652078774617e-05, 'epoch': 2.31}\n",
      "{'loss': 0.4706, 'grad_norm': 1.4296875, 'learning_rate': 2.2684172137126186e-05, 'epoch': 2.32}\n",
      "{'loss': 0.5009, 'grad_norm': 2.0, 'learning_rate': 2.2501823486506202e-05, 'epoch': 2.32}\n",
      "{'loss': 0.4928, 'grad_norm': 1.5078125, 'learning_rate': 2.2319474835886215e-05, 'epoch': 2.33}\n",
      "{'loss': 0.5054, 'grad_norm': 2.4375, 'learning_rate': 2.213712618526623e-05, 'epoch': 2.34}\n",
      "{'loss': 0.5069, 'grad_norm': 2.0625, 'learning_rate': 2.1954777534646247e-05, 'epoch': 2.34}\n",
      "{'loss': 0.529, 'grad_norm': 1.4296875, 'learning_rate': 2.177242888402626e-05, 'epoch': 2.35}\n",
      "{'loss': 0.5143, 'grad_norm': 1.546875, 'learning_rate': 2.1590080233406275e-05, 'epoch': 2.35}\n",
      "{'loss': 0.5478, 'grad_norm': 2.453125, 'learning_rate': 2.1407731582786288e-05, 'epoch': 2.36}\n",
      "{'loss': 0.4916, 'grad_norm': 1.640625, 'learning_rate': 2.12253829321663e-05, 'epoch': 2.36}\n",
      "{'loss': 0.5392, 'grad_norm': 2.0625, 'learning_rate': 2.1043034281546316e-05, 'epoch': 2.37}\n",
      "{'loss': 0.541, 'grad_norm': 2.046875, 'learning_rate': 2.0860685630926332e-05, 'epoch': 2.37}\n",
      "{'loss': 0.505, 'grad_norm': 2.765625, 'learning_rate': 2.0678336980306344e-05, 'epoch': 2.38}\n",
      "{'loss': 0.5134, 'grad_norm': 1.9765625, 'learning_rate': 2.049598832968636e-05, 'epoch': 2.38}\n",
      "{'loss': 0.5525, 'grad_norm': 1.625, 'learning_rate': 2.0313639679066376e-05, 'epoch': 2.39}\n",
      "{'loss': 0.5331, 'grad_norm': 1.5546875, 'learning_rate': 2.0131291028446392e-05, 'epoch': 2.4}\n",
      "{'loss': 0.4996, 'grad_norm': 2.296875, 'learning_rate': 1.9948942377826405e-05, 'epoch': 2.4}\n",
      "{'loss': 0.5038, 'grad_norm': 1.921875, 'learning_rate': 1.976659372720642e-05, 'epoch': 2.41}\n",
      "{'loss': 0.4742, 'grad_norm': 0.875, 'learning_rate': 1.9584245076586437e-05, 'epoch': 2.41}\n",
      "{'loss': 0.5223, 'grad_norm': 1.34375, 'learning_rate': 1.940189642596645e-05, 'epoch': 2.42}\n",
      "{'loss': 0.5807, 'grad_norm': 1.6875, 'learning_rate': 1.9219547775346465e-05, 'epoch': 2.42}\n",
      "{'loss': 0.4596, 'grad_norm': 1.453125, 'learning_rate': 1.9037199124726478e-05, 'epoch': 2.43}\n",
      "{'loss': 0.4292, 'grad_norm': 1.84375, 'learning_rate': 1.8854850474106493e-05, 'epoch': 2.43}\n",
      "{'loss': 0.5046, 'grad_norm': 1.40625, 'learning_rate': 1.8672501823486506e-05, 'epoch': 2.44}\n",
      "{'loss': 0.547, 'grad_norm': 1.6796875, 'learning_rate': 1.8490153172866522e-05, 'epoch': 2.45}\n",
      "{'loss': 0.5404, 'grad_norm': 1.9609375, 'learning_rate': 1.8307804522246534e-05, 'epoch': 2.45}\n",
      "{'loss': 0.4974, 'grad_norm': 2.015625, 'learning_rate': 1.812545587162655e-05, 'epoch': 2.46}\n",
      "{'loss': 0.4489, 'grad_norm': 1.734375, 'learning_rate': 1.7943107221006566e-05, 'epoch': 2.46}\n",
      "{'loss': 0.5328, 'grad_norm': 1.3125, 'learning_rate': 1.776075857038658e-05, 'epoch': 2.47}\n",
      "{'loss': 0.4601, 'grad_norm': 1.734375, 'learning_rate': 1.7578409919766595e-05, 'epoch': 2.47}\n",
      "{'loss': 0.514, 'grad_norm': 1.78125, 'learning_rate': 1.739606126914661e-05, 'epoch': 2.48}\n",
      "{'loss': 0.4656, 'grad_norm': 1.7734375, 'learning_rate': 1.7213712618526623e-05, 'epoch': 2.48}\n",
      "{'loss': 0.5144, 'grad_norm': 2.734375, 'learning_rate': 1.703136396790664e-05, 'epoch': 2.49}\n",
      "{'loss': 0.5466, 'grad_norm': 1.359375, 'learning_rate': 1.6849015317286655e-05, 'epoch': 2.49}\n",
      "{'loss': 0.5126, 'grad_norm': 2.15625, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.5}\n",
      "{'loss': 0.515, 'grad_norm': 1.8671875, 'learning_rate': 1.6484318016046683e-05, 'epoch': 2.51}\n",
      "{'loss': 0.465, 'grad_norm': 2.203125, 'learning_rate': 1.6301969365426696e-05, 'epoch': 2.51}\n",
      "{'loss': 0.4475, 'grad_norm': 1.78125, 'learning_rate': 1.6119620714806712e-05, 'epoch': 2.52}\n",
      "{'loss': 0.5018, 'grad_norm': 1.765625, 'learning_rate': 1.5937272064186724e-05, 'epoch': 2.52}\n",
      "{'loss': 0.5812, 'grad_norm': 2.046875, 'learning_rate': 1.575492341356674e-05, 'epoch': 2.53}\n",
      "{'loss': 0.4957, 'grad_norm': 1.5703125, 'learning_rate': 1.5572574762946753e-05, 'epoch': 2.53}\n",
      "{'loss': 0.5251, 'grad_norm': 2.109375, 'learning_rate': 1.539022611232677e-05, 'epoch': 2.54}\n",
      "{'loss': 0.5273, 'grad_norm': 2.015625, 'learning_rate': 1.5207877461706785e-05, 'epoch': 2.54}\n",
      "{'loss': 0.4576, 'grad_norm': 1.203125, 'learning_rate': 1.5025528811086797e-05, 'epoch': 2.55}\n",
      "{'loss': 0.5462, 'grad_norm': 2.515625, 'learning_rate': 1.4843180160466813e-05, 'epoch': 2.55}\n",
      "{'loss': 0.4182, 'grad_norm': 1.421875, 'learning_rate': 1.4660831509846829e-05, 'epoch': 2.56}\n",
      "{'loss': 0.5411, 'grad_norm': 1.6484375, 'learning_rate': 1.4478482859226841e-05, 'epoch': 2.57}\n",
      "{'loss': 0.4276, 'grad_norm': 2.15625, 'learning_rate': 1.4296134208606857e-05, 'epoch': 2.57}\n",
      "{'loss': 0.4897, 'grad_norm': 1.09375, 'learning_rate': 1.4113785557986872e-05, 'epoch': 2.58}\n",
      "{'loss': 0.5408, 'grad_norm': 2.234375, 'learning_rate': 1.3931436907366884e-05, 'epoch': 2.58}\n",
      "{'loss': 0.5643, 'grad_norm': 1.3515625, 'learning_rate': 1.37490882567469e-05, 'epoch': 2.59}\n",
      "{'loss': 0.4645, 'grad_norm': 2.140625, 'learning_rate': 1.3566739606126916e-05, 'epoch': 2.59}\n",
      "{'loss': 0.557, 'grad_norm': 2.015625, 'learning_rate': 1.3384390955506929e-05, 'epoch': 2.6}\n",
      "{'loss': 0.5047, 'grad_norm': 1.6953125, 'learning_rate': 1.3202042304886944e-05, 'epoch': 2.6}\n",
      "{'loss': 0.4722, 'grad_norm': 1.484375, 'learning_rate': 1.301969365426696e-05, 'epoch': 2.61}\n",
      "{'loss': 0.5513, 'grad_norm': 1.6953125, 'learning_rate': 1.2837345003646975e-05, 'epoch': 2.61}\n",
      "{'loss': 0.4933, 'grad_norm': 1.265625, 'learning_rate': 1.2654996353026987e-05, 'epoch': 2.62}\n",
      "{'loss': 0.4936, 'grad_norm': 2.0, 'learning_rate': 1.2472647702407003e-05, 'epoch': 2.63}\n",
      "{'loss': 0.5447, 'grad_norm': 2.96875, 'learning_rate': 1.2290299051787017e-05, 'epoch': 2.63}\n",
      "{'loss': 0.5779, 'grad_norm': 1.7890625, 'learning_rate': 1.2107950401167031e-05, 'epoch': 2.64}\n",
      "{'loss': 0.4929, 'grad_norm': 2.03125, 'learning_rate': 1.1925601750547047e-05, 'epoch': 2.64}\n",
      "{'loss': 0.4837, 'grad_norm': 1.3125, 'learning_rate': 1.1743253099927062e-05, 'epoch': 2.65}\n",
      "{'loss': 0.4926, 'grad_norm': 1.953125, 'learning_rate': 1.1560904449307076e-05, 'epoch': 2.65}\n",
      "{'loss': 0.4987, 'grad_norm': 2.40625, 'learning_rate': 1.137855579868709e-05, 'epoch': 2.66}\n",
      "{'loss': 0.5193, 'grad_norm': 1.9453125, 'learning_rate': 1.1196207148067104e-05, 'epoch': 2.66}\n",
      "{'loss': 0.4817, 'grad_norm': 2.578125, 'learning_rate': 1.1013858497447118e-05, 'epoch': 2.67}\n",
      "{'loss': 0.4852, 'grad_norm': 2.078125, 'learning_rate': 1.0831509846827134e-05, 'epoch': 2.67}\n",
      "{'loss': 0.5548, 'grad_norm': 1.7109375, 'learning_rate': 1.0649161196207149e-05, 'epoch': 2.68}\n",
      "{'loss': 0.5074, 'grad_norm': 2.03125, 'learning_rate': 1.0466812545587164e-05, 'epoch': 2.69}\n",
      "{'loss': 0.5088, 'grad_norm': 1.75, 'learning_rate': 1.0284463894967179e-05, 'epoch': 2.69}\n",
      "{'loss': 0.4317, 'grad_norm': 1.546875, 'learning_rate': 1.0102115244347191e-05, 'epoch': 2.7}\n",
      "{'loss': 0.5707, 'grad_norm': 2.234375, 'learning_rate': 9.919766593727207e-06, 'epoch': 2.7}\n",
      "{'loss': 0.5088, 'grad_norm': 1.4296875, 'learning_rate': 9.737417943107221e-06, 'epoch': 2.71}\n",
      "{'loss': 0.5223, 'grad_norm': 1.7578125, 'learning_rate': 9.555069292487236e-06, 'epoch': 2.71}\n",
      "{'loss': 0.4928, 'grad_norm': 2.515625, 'learning_rate': 9.372720641867251e-06, 'epoch': 2.72}\n",
      "{'loss': 0.5415, 'grad_norm': 1.890625, 'learning_rate': 9.190371991247266e-06, 'epoch': 2.72}\n",
      "{'loss': 0.6071, 'grad_norm': 2.09375, 'learning_rate': 9.00802334062728e-06, 'epoch': 2.73}\n",
      "{'loss': 0.5391, 'grad_norm': 2.15625, 'learning_rate': 8.825674690007294e-06, 'epoch': 2.74}\n",
      "{'loss': 0.5198, 'grad_norm': 1.6484375, 'learning_rate': 8.643326039387308e-06, 'epoch': 2.74}\n",
      "{'loss': 0.5393, 'grad_norm': 1.9765625, 'learning_rate': 8.460977388767323e-06, 'epoch': 2.75}\n",
      "{'loss': 0.4734, 'grad_norm': 1.5703125, 'learning_rate': 8.278628738147339e-06, 'epoch': 2.75}\n",
      "{'loss': 0.5034, 'grad_norm': 1.9453125, 'learning_rate': 8.096280087527353e-06, 'epoch': 2.76}\n",
      "{'loss': 0.5741, 'grad_norm': 2.546875, 'learning_rate': 7.913931436907367e-06, 'epoch': 2.76}\n",
      "{'loss': 0.4644, 'grad_norm': 1.890625, 'learning_rate': 7.731582786287383e-06, 'epoch': 2.77}\n",
      "{'loss': 0.5017, 'grad_norm': 1.65625, 'learning_rate': 7.549234135667396e-06, 'epoch': 2.77}\n",
      "{'loss': 0.5072, 'grad_norm': 1.78125, 'learning_rate': 7.3668854850474105e-06, 'epoch': 2.78}\n",
      "{'loss': 0.4797, 'grad_norm': 1.53125, 'learning_rate': 7.1845368344274255e-06, 'epoch': 2.78}\n",
      "{'loss': 0.6087, 'grad_norm': 2.375, 'learning_rate': 7.00218818380744e-06, 'epoch': 2.79}\n",
      "{'loss': 0.5436, 'grad_norm': 2.09375, 'learning_rate': 6.819839533187456e-06, 'epoch': 2.8}\n",
      "{'loss': 0.516, 'grad_norm': 1.3515625, 'learning_rate': 6.63749088256747e-06, 'epoch': 2.8}\n",
      "{'loss': 0.5243, 'grad_norm': 2.3125, 'learning_rate': 6.455142231947483e-06, 'epoch': 2.81}\n",
      "{'loss': 0.4801, 'grad_norm': 2.203125, 'learning_rate': 6.272793581327499e-06, 'epoch': 2.81}\n",
      "{'loss': 0.4555, 'grad_norm': 1.234375, 'learning_rate': 6.090444930707513e-06, 'epoch': 2.82}\n",
      "{'loss': 0.4903, 'grad_norm': 1.5390625, 'learning_rate': 5.908096280087528e-06, 'epoch': 2.82}\n",
      "{'loss': 0.477, 'grad_norm': 2.1875, 'learning_rate': 5.725747629467542e-06, 'epoch': 2.83}\n",
      "{'loss': 0.5304, 'grad_norm': 1.9921875, 'learning_rate': 5.543398978847557e-06, 'epoch': 2.83}\n",
      "{'loss': 0.4822, 'grad_norm': 1.5859375, 'learning_rate': 5.361050328227572e-06, 'epoch': 2.84}\n",
      "{'loss': 0.5532, 'grad_norm': 1.8359375, 'learning_rate': 5.178701677607585e-06, 'epoch': 2.84}\n",
      "{'loss': 0.51, 'grad_norm': 2.390625, 'learning_rate': 4.9963530269876e-06, 'epoch': 2.85}\n",
      "{'loss': 0.4859, 'grad_norm': 2.46875, 'learning_rate': 4.8140043763676155e-06, 'epoch': 2.86}\n",
      "{'loss': 0.5355, 'grad_norm': 2.234375, 'learning_rate': 4.63165572574763e-06, 'epoch': 2.86}\n",
      "{'loss': 0.4539, 'grad_norm': 1.75, 'learning_rate': 4.449307075127644e-06, 'epoch': 2.87}\n",
      "{'loss': 0.5267, 'grad_norm': 2.84375, 'learning_rate': 4.266958424507659e-06, 'epoch': 2.87}\n",
      "{'loss': 0.4606, 'grad_norm': 2.3125, 'learning_rate': 4.084609773887674e-06, 'epoch': 2.88}\n",
      "{'loss': 0.5042, 'grad_norm': 1.6484375, 'learning_rate': 3.902261123267688e-06, 'epoch': 2.88}\n",
      "{'loss': 0.5901, 'grad_norm': 2.625, 'learning_rate': 3.7199124726477025e-06, 'epoch': 2.89}\n",
      "{'loss': 0.4885, 'grad_norm': 1.609375, 'learning_rate': 3.5375638220277175e-06, 'epoch': 2.89}\n",
      "{'loss': 0.4542, 'grad_norm': 1.3203125, 'learning_rate': 3.3552151714077313e-06, 'epoch': 2.9}\n",
      "{'loss': 0.4944, 'grad_norm': 1.890625, 'learning_rate': 3.1728665207877464e-06, 'epoch': 2.9}\n",
      "{'loss': 0.4774, 'grad_norm': 1.96875, 'learning_rate': 2.9905178701677606e-06, 'epoch': 2.91}\n",
      "{'loss': 0.5344, 'grad_norm': 2.375, 'learning_rate': 2.8081692195477757e-06, 'epoch': 2.92}\n",
      "{'loss': 0.5119, 'grad_norm': 1.78125, 'learning_rate': 2.62582056892779e-06, 'epoch': 2.92}\n",
      "{'loss': 0.53, 'grad_norm': 2.078125, 'learning_rate': 2.4434719183078045e-06, 'epoch': 2.93}\n",
      "{'loss': 0.5506, 'grad_norm': 2.109375, 'learning_rate': 2.261123267687819e-06, 'epoch': 2.93}\n",
      "{'loss': 0.4725, 'grad_norm': 1.6328125, 'learning_rate': 2.078774617067834e-06, 'epoch': 2.94}\n",
      "{'loss': 0.5106, 'grad_norm': 1.890625, 'learning_rate': 1.8964259664478485e-06, 'epoch': 2.94}\n",
      "{'loss': 0.5172, 'grad_norm': 1.9921875, 'learning_rate': 1.714077315827863e-06, 'epoch': 2.95}\n",
      "{'loss': 0.6232, 'grad_norm': 1.953125, 'learning_rate': 1.5317286652078775e-06, 'epoch': 2.95}\n",
      "{'loss': 0.5259, 'grad_norm': 1.3671875, 'learning_rate': 1.3493800145878922e-06, 'epoch': 2.96}\n",
      "{'loss': 0.5244, 'grad_norm': 1.7265625, 'learning_rate': 1.1670313639679066e-06, 'epoch': 2.96}\n",
      "{'loss': 0.5298, 'grad_norm': 1.7890625, 'learning_rate': 9.846827133479213e-07, 'epoch': 2.97}\n",
      "{'loss': 0.4943, 'grad_norm': 2.171875, 'learning_rate': 8.023340627279359e-07, 'epoch': 2.98}\n",
      "{'loss': 0.5163, 'grad_norm': 2.5, 'learning_rate': 6.199854121079504e-07, 'epoch': 2.98}\n",
      "{'loss': 0.6086, 'grad_norm': 2.09375, 'learning_rate': 4.37636761487965e-07, 'epoch': 2.99}\n",
      "{'loss': 0.4987, 'grad_norm': 1.984375, 'learning_rate': 2.5528811086797963e-07, 'epoch': 2.99}\n",
      "{'loss': 0.5304, 'grad_norm': 1.8359375, 'learning_rate': 7.293946024799416e-08, 'epoch': 3.0}\n",
      "{'train_runtime': 7202.4372, 'train_samples_per_second': 6.092, 'train_steps_per_second': 0.761, 'train_loss': 0.5820217862083997, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "trainer.train()\n",
    "trainer.save_model(\"./qwen2-lora-finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea0629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/face_craft_env/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c09399430334b87b3b392b26273f2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference Pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "finetuned_model = \"../models/qwen2-lora-finetuned\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=finetuned_model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "# Beispiel-Prompt mit instruction-style\n",
    "prompt = (\n",
    "    \"### Instruction:\\n\"\n",
    "    \"Wie ist der aktuelle Stand der OAuth2-Migration beim Projekt Atlas?\\n\\n\"\n",
    "    \"### Response:\\n\"\n",
    ")\n",
    "\n",
    "output = pipe(prompt, max_new_tokens=100)\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eae3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_craft_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
